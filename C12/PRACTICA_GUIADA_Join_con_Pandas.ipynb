{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica guiada - Join con Pandas\n",
    "\n",
    "# PARTE I\n",
    "\n",
    "* Algunas de las operaciones más interesantes con los datos provienen de la combinación de diferentes fuentes de datos. Estas operaciones pueden ser\n",
    "\n",
    "    1. simples concatenaciones de datos de datasets diferentes\n",
    "    2. operaciones más similares a un join o merge en una base de datos\n",
    "\n",
    "* Tanto `Series` como `DataFrames` fueron construidos teniendo estas operaciones en mente e incluyen funciones y métodos para realizarlas de forma rápida y simple.\n",
    "\n",
    "* Veremos dos operaciones: `pd.append` y `pd.concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una función que crea un `DataFrame` para simplificar algunos pasos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(cols, ind):\n",
    "    \"\"\"Quickly make a DataFrame\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind]\n",
    "            for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "# example DataFrame\n",
    "make_df('ABC', range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También vamos a crear una clase para poder imprimir \"side by side\" diferentes `DataFrame`. La idea es poder visualizar algunas de las operaciones que vamos a realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenación simple con ``pd.concat``\n",
    "\n",
    "* ``pd.concat()``, permite hacer concatenaciones simples de diferentes `Series`.\n",
    "\n",
    "* Tiene una sintaxis similar a su análoga en Numpy ``np.concatenate``. Pero contiene algunas opciones más:\n",
    "\n",
    "```python\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
    "ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
    "pd.concat([ser1, ser2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También permite concater objetos de mayor dimensionalidad como `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = make_df('AB', [1, 2])\n",
    "df2 = make_df('AB', [3, 4])\n",
    "display('df1', 'df2', 'pd.concat([df1, df2])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por defecto, la concatenación se hace en el sentido de las filas del ``DataFrame`` (i.e., ``axis=0``).\n",
    "* Puede especificarse el eje sobre cual realizar la concatenación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = make_df('AB', [0, 1])\n",
    "df4 = make_df('CD', [0, 1])\n",
    "display('df3', 'df4', \"pd.concat([df3, df4], axis='columns')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índice duplicados\n",
    "\n",
    "Recordemos que numpy también presenta un método de concatenación.\n",
    "\n",
    "Una diferencia importante entre  ``np.concatenate`` y ``pd.concat`` es que la concatenación de Pandas preserva los índices, incluso si el resultado implica índices duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = make_df('AB', [0, 1])\n",
    "y = make_df('AB', [2, 3])\n",
    "y.index = x.index  # índices duplicados!\n",
    "display('x','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('x', 'y', 'pd.concat([x, y])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien `DataFrame` permite índices duplicados es preferible eviatarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando la existencia índices duplicados\n",
    "\n",
    "* Podemos verificar si existen índices solapados en el resultado de ``pd.concat()`` usando una ``verify_integrity`` flag.\n",
    "\n",
    "* Al setear esto en True, la concatenación arrojará una excepción si existe algún índice duplicado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El parámetro verify_integrity evita que concatenemos dataframes con índices iguales.\n",
    "pd.concat([x, y], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En general, para no recibir este comportamiento frente a un error, podemos generar una excepción para mostrarselo\n",
    "# al usuario de forma más prolija\n",
    "try:\n",
    "    pd.concat([x, y], verify_integrity=True)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignorando el índice\n",
    "\n",
    "* En algunos casos el índice no importa u podemos ignorarlo: simplemente usamos nuevamente ``ignore_index``. Al setearlo en True, se genera un nuevo índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('x', 'y', 'pd.concat([x, y], ignore_index=True)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El método ``append()``\n",
    "\n",
    "* Dado que la concatenación de arrays es bastante común, ``Series`` y ``DataFrame``tienen un método ``append`` \n",
    "\n",
    "* Por ejemplo, en lugar de llamar ``pd.concat([df1, df2])``, es posible llamar al más sencillo ``df1.append(df2)``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display('df1', 'df2', 'df1.append(df2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **IMPORTANTE:** tener en cuenta que, a diferencia del método `append` de listas, el `append()` de Pandas no modifica el objeto original. Genera un nuevo objeto con los datos combinados.\n",
    "* Dado que esto implica crear un índice nuevo y un nuevo dataset `append` puede no ser el mejor método si se planea concatenar muchos datasets seguidos.\n",
    "* En estos casos es mejor usar la función `pd.concat()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE II \n",
    "\n",
    "## Tipos de relaciones\n",
    "\n",
    "Una de las características más valiosas de la librería Pandas es su funcionalidad para realizar joins en memoria y de manera eficiente.\n",
    "\n",
    "El método merge() permite trabajar con objetos que presentan distintos tipos de relaciones:\n",
    " 1. Uno a uno\n",
    " 2. Muchos a uno\n",
    " 3. Muchos a muchos\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Join uno a uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vemos que cada empleado tiene un sólo grupo y una sola fecha de contratación.\n",
    "# Combinamos los dataframes usando pd.merge()\n",
    "# Notar que la función merge encontró la única columna en común entre los dos dataframe (\"employee\"). \n",
    "# La función requiere que la columna tenga el mismo nombre en los dos df.\n",
    "df3 = pd.merge(df1, df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Join uno a muchos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
    "                    'supervisor': ['Carly', 'Guido', 'Steve']})\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notar que cada supervisor pertenece a UN grupo que puede tener MUCHOS empleados.\n",
    "# En el join entre empleados y supervisores, los empleados aparecerán una sola vez pero los supervisores\n",
    "# pueden repetirse.\n",
    "print (pd.merge(df3, df4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Join muchos a muchos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
    "                               'spreadsheets', 'organization']})\n",
    "print(df5)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notar que cada grupo tiene MUCHOS skills asociados y a su vez pueden pertenecer a él MUCHOS empleados\n",
    "# Por lo tanto el join entre la tabla de skills y la de empleados es de MUCHOS a MUCHOS.\n",
    "# Vamos a ver en el resultado que tanto los skills como los empleados pueden repetirse.\n",
    "df6 = pd.merge(df1, df5)\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins por diferentes columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede suceder que en nuestros dataframes no haya una única columna con el mismo nombre en ambas tablas para poder hacer el join. \n",
    "Para resolver este problema, Pandas implementa los parámetros \"on\", \"right_on\" y \"left_on\" donde podemos especificar por cuáles columnas vamos a unir los datos. \n",
    "\n",
    "### 1. Join con \"on\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='employee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Join con \"left_on\" y \"right_on\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "print(df1)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Join por más de una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df7 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
    "                               'spreadsheets', 'organization'],\n",
    "                    'tools':  ['calculator','desktop computer','laptop computer','server','desktop computer','board']\n",
    "                    })\n",
    "print(df6)\n",
    "print(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ahora podemos ver las herramientas por empleado.\n",
    "\n",
    "pd.merge(df6,df7,left_on=['group','skills'], right_on = ['group','skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Como los nombres de las columnas son iguales, utilizar sólo \"on\" es equivalente.\n",
    "pd.merge(df6,df7,on=['group','skills'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Left joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "raw_data = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "df_a = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': ['4', '5', '6', '7', '8'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "df_b = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilizando el valor left en la forma del join produce una lista completa de las filas de df_a, \n",
    "# con las filas que matchean de df_b. Si no hay matcheo, las columnas que vienen de df_b serán nulas:\n",
    "pd.merge(df_a, df_b, on='subject_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: Cual sería el resultado de cambiar left por right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inner y outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Como mencionamos antes utilizar la forma outer (OUTER JOIN) \n",
    "# produce un conjunto de todas las filas en df_a o df_b. \n",
    "# Todas las columnas tendran valores si la fila de un lado tiene su correspondiente en el otro.\n",
    "# Si no hya matcheo las columnas del que no había valor se completan con null.\n",
    "pd.merge(df_a, df_b, on='subject_id', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: Qué pasaría si usamos un inner join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando los casos que se aparecen en un dataframe pero no en otro con left join.\n",
    "\n",
    "Un problema común que podemos querer resolver es encontrar los casos que se encuentran en una tabla pero no en otra. Esto se puede hacer fácilmente con un left join por el o los campos que conforman la clave. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data = {'col1' : [1, 2, 3, 4, 5], 'col2' : [10, 11, 12, 13, 14]}) \n",
    "df2 = pd.DataFrame(data = {'col1' : [1, 2, 3], 'col2' : [10, 11, 12]})\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agrego en ambos dataframes unas claves que toman siempre el mismo valor para después poder compararlas.\n",
    "df1['key1'] = 1\n",
    "df2['key2'] = 1\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cuando hacemos el left join, los valores de key2 se llenan con null para los valores de df2 que no existen en df1\n",
    "df1 = pd.merge(df1, df2, on=['col1', 'col2'], how = 'left')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subseteo el resultado del merge para quedarme con los que aparecen en df1 pero no en df2.\n",
    "df3 = df1[~(df1.key2 == df1.key1)]\n",
    "df3 = df3.drop(['key1','key2'], axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de buenas prácticas de performance\n",
    "\n",
    "El método join, cuenta con la misma sintaxis y posibilidades que el método merge pero con la diferencia de que siempre hace la relación por el index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dos Dataframes de tamaño 1000000\n",
    "df1 = pd.DataFrame(np.arange(1000000), columns=['A'])\n",
    "df1['B'] = np.random.randint(0,1000,(1000000))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.arange(1000000), columns=['A2'])\n",
    "df2['B2'] = np.random.randint(0,1000,(1000000))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Medimos el tiempo de ejecución del merge\n",
    "def a():\n",
    "    x = df1.merge(df2, how='left', left_on='A', right_on='A2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Medimos el tiempo de ejecución del join\n",
    "def b():\n",
    "    x = df1.set_index('A').join(df2.set_index('A2'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dos Dataframes de tamaño 1000000\n",
    "df1 = pd.DataFrame(np.arange(1000000), columns=['A'])\n",
    "df1['B'] = np.random.randint(0,1000,(1000000))\n",
    "df2 = pd.DataFrame(np.arange(1000000), columns=['A2'])\n",
    "df2['B2'] = np.random.randint(0,1000,(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_indA(df):\n",
    "     df.set_index('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_indA2(df):\n",
    "    df.set_index('A2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def c():\n",
    "    df1.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit set_indA(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit set_indA2(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  Trabajo con series de tiempo: calcular variaciones con shift()\n",
    "\n",
    "Cuando se trabaja con series de tiempo, es muy habitual trabajar agregar al dataframe una variable que indique cuánto se modificó determinado valor desde la última medición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creamos el dataframe\n",
    "df= pd.DataFrame()\n",
    "# Agregamos las series de datos\n",
    "df['hora']=['10:30','10:31','10:38','10:40','10:41']\n",
    "df['cantidad']=[20,20,9,12,12]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cantidad_anterior'] = df['cantidad'].shift(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['variacion'] = df['cantidad'] - df['cantidad_anterior']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variaciones con agrupamiento\n",
    "\n",
    "Es muy habitual tener que calcular esto mismo pero por cada individuo o categoría que interesa estudiar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['operador']=['Q8','Q8','Q8','Q7','Q9','Q9']\n",
    "df['hora']=['10:30','10:31','10:32','10:38','10:40','10:41']\n",
    "df['cantidad']=[15,20,10,9,12,12]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cantidad_ant_operador'] = df.groupby(['operador'])['cantidad'].transform(lambda x:x.shift())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['variacion_operador'] = df['cantidad'] - df['cantidad_ant_operador']\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
