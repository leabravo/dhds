{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESAFIO 2. Datos de Billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1. Explorar los datos\n",
    "\n",
    "Cargá el dataset usando Pandas y comenzá a explorar los datos. Guardá en este espacio todos los procesos y análisis exploratorios que hayas hecho, tanto los preliminares como los definitivos. Por favor, indicá cuál(es) es(son) cada uno(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./billboard.csv', encoding='latin8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribí un breve descripción de los datos. Hacé particular énfasis en los hallazagos que te parezcan relevantes hasta este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year   artist.inverted             track  time genre date.entered  \\\n",
      "312  2000  Ghostface Killah  Cherchez LaGhost  3:04   R&B   2000-08-05   \n",
      "313  2000       Smith, Will       Freakin' It  3:58   Rap   2000-02-12   \n",
      "314  2000     Zombie Nation     Kernkraft 400  3:30  Rock   2000-09-02   \n",
      "315  2000    Eastsidaz, The          Got Beef  3:58   Rap   2000-07-01   \n",
      "316  2000            Fragma    Toca's Miracle  3:22   R&B   2000-10-28   \n",
      "\n",
      "    date.peaked  x1st.week  x2nd.week  x3rd.week     ...      x67th.week  \\\n",
      "312  2000-08-05         98        NaN        NaN     ...             NaN   \n",
      "313  2000-02-12         99       99.0       99.0     ...             NaN   \n",
      "314  2000-09-02         99       99.0        NaN     ...             NaN   \n",
      "315  2000-07-01         99       99.0        NaN     ...             NaN   \n",
      "316  2000-10-28         99        NaN        NaN     ...             NaN   \n",
      "\n",
      "     x68th.week  x69th.week  x70th.week  x71st.week  x72nd.week  x73rd.week  \\\n",
      "312         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "313         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "314         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "315         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "316         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "     x74th.week  x75th.week  x76th.week  \n",
      "312         NaN         NaN         NaN  \n",
      "313         NaN         NaN         NaN  \n",
      "314         NaN         NaN         NaN  \n",
      "315         NaN         NaN         NaN  \n",
      "316         NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 83 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 317 entries, 0 to 316\n",
      "Data columns (total 83 columns):\n",
      "year               317 non-null int64\n",
      "artist.inverted    317 non-null object\n",
      "track              317 non-null object\n",
      "time               317 non-null object\n",
      "genre              317 non-null object\n",
      "date.entered       317 non-null object\n",
      "date.peaked        317 non-null object\n",
      "x1st.week          317 non-null int64\n",
      "x2nd.week          312 non-null float64\n",
      "x3rd.week          307 non-null float64\n",
      "x4th.week          300 non-null float64\n",
      "x5th.week          292 non-null float64\n",
      "x6th.week          280 non-null float64\n",
      "x7th.week          269 non-null float64\n",
      "x8th.week          260 non-null float64\n",
      "x9th.week          253 non-null float64\n",
      "x10th.week         244 non-null float64\n",
      "x11th.week         236 non-null float64\n",
      "x12th.week         222 non-null float64\n",
      "x13th.week         210 non-null float64\n",
      "x14th.week         204 non-null float64\n",
      "x15th.week         197 non-null float64\n",
      "x16th.week         182 non-null float64\n",
      "x17th.week         177 non-null float64\n",
      "x18th.week         166 non-null float64\n",
      "x19th.week         156 non-null float64\n",
      "x20th.week         146 non-null float64\n",
      "x21st.week         65 non-null float64\n",
      "x22nd.week         55 non-null float64\n",
      "x23rd.week         48 non-null float64\n",
      "x24th.week         46 non-null float64\n",
      "x25th.week         38 non-null float64\n",
      "x26th.week         36 non-null float64\n",
      "x27th.week         29 non-null float64\n",
      "x28th.week         24 non-null float64\n",
      "x29th.week         20 non-null float64\n",
      "x30th.week         20 non-null float64\n",
      "x31st.week         19 non-null float64\n",
      "x32nd.week         18 non-null float64\n",
      "x33rd.week         12 non-null float64\n",
      "x34th.week         10 non-null float64\n",
      "x35th.week         9 non-null float64\n",
      "x36th.week         9 non-null float64\n",
      "x37th.week         9 non-null float64\n",
      "x38th.week         8 non-null float64\n",
      "x39th.week         8 non-null float64\n",
      "x40th.week         7 non-null float64\n",
      "x41st.week         7 non-null float64\n",
      "x42nd.week         6 non-null float64\n",
      "x43rd.week         6 non-null float64\n",
      "x44th.week         6 non-null float64\n",
      "x45th.week         5 non-null float64\n",
      "x46th.week         5 non-null float64\n",
      "x47th.week         5 non-null float64\n",
      "x48th.week         4 non-null float64\n",
      "x49th.week         4 non-null float64\n",
      "x50th.week         4 non-null float64\n",
      "x51st.week         4 non-null float64\n",
      "x52nd.week         4 non-null float64\n",
      "x53rd.week         4 non-null float64\n",
      "x54th.week         2 non-null float64\n",
      "x55th.week         2 non-null float64\n",
      "x56th.week         2 non-null float64\n",
      "x57th.week         2 non-null float64\n",
      "x58th.week         2 non-null float64\n",
      "x59th.week         2 non-null float64\n",
      "x60th.week         2 non-null float64\n",
      "x61st.week         2 non-null float64\n",
      "x62nd.week         2 non-null float64\n",
      "x63rd.week         2 non-null float64\n",
      "x64th.week         2 non-null float64\n",
      "x65th.week         1 non-null float64\n",
      "x66th.week         0 non-null float64\n",
      "x67th.week         0 non-null float64\n",
      "x68th.week         0 non-null float64\n",
      "x69th.week         0 non-null float64\n",
      "x70th.week         0 non-null float64\n",
      "x71st.week         0 non-null float64\n",
      "x72nd.week         0 non-null float64\n",
      "x73rd.week         0 non-null float64\n",
      "x74th.week         0 non-null float64\n",
      "x75th.week         0 non-null float64\n",
      "x76th.week         0 non-null float64\n",
      "dtypes: float64(75), int64(2), object(6)\n",
      "memory usage: 205.6+ KB\n"
     ]
    }
   ],
   "source": [
    "print(data.tail())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2. Limpieza de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezá por una limpieza rudimentaria. Reformulá los nombres desprolijos de las variables para que tengan un criterio común, acortá los strings que sean muy largos, buscá datos missing y realizá una imputación (en caso de que te parezca que esto es necesario). En aquellos casos en que decidas que es necesario imputar, explicá cuál es el motivo y justificá la técnica que hayas utilizado para imputar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la función `melt()` de Pandas, reformateá el dataset para que tengan el formato \"long\" en lugar de \"wide\". Como resultado deberías haber removido la columna 72 'week' y la deberías haber reemplazado por dos: 'Week' y 'Ranking'. Ahora vas a tener múltiples entradas por canción: una por cada semana que haya estado en el ranking de Billboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3. Visualizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la herramienta de plotting de tu elección, generá visualizaciones que permitan seguir profundizando en el análisis exploratorio de tus datos. No hay un máximo o mínimo de gráficos. Lo que sí es requisito es que haya una lógica y un sentido en la generación de los mismos: tiene que generarse una \"historia\" clara a partir de los mismos. También deberías en este punto realizar un análisis preliminar de los datos: forma de la distribución, estadísticos y relaciones entre las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4. Planteo del problema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenés hecho el análisis exploratorio del dataset. Ahora es necesario realizar una formulación clara del problema que se va a abordar. Podés incorporar datos externos al dataset, si resultan necesarios para la resolución del problema formulado -solamente, acordate de poner un link a los mismos-. La creatividad es fundamental en este paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5. Brainstorming para abordar el problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En forma de listado, comenzá a pensar cuáles serían las formas en que podrías abordar el problema planteado más arriba. No tiene que ser necesariamente un código. Más bien, la idea es idear diferentes estrategias para aprovechar al máximo los datos disponibles en función del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6. Crear un reporte con los hallazgos, el código y las visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creá un reporte que describa cada uno de los seis pasos previos. Imaginá que estás describiendo tus datos, visualizaciones, problemas, hallazgos y conclusiones con tus pares. Deberá tener al menos 500 palabras. Y deberá contener el código utilizado para generar las visualizaciones, las pruebas estadísticas realizadas -y cualquier otro método que hayas utilizado- y el análisis e interpretación de los resultados- propiamente dicho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: El mismo programa para el que trabajaste te solicita escribir un white paper de al menos 500 palabras sobre el tema \"cómo lidiar con la limpieza de los datos\". El objetivo es que constituya una presentación para exponer ante una audiencia amplia, así que va a ser necesario incluir casos reales como ejemplos para sustentar tus planteos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pista: para empezar hacé una primera búsqueda en internet de artículos, blogposts, papers, videos, etc. En fin... todo lo que  te sirva para entender los desafíos que implica trabajar con datos. Este white paper debería constituir una reflexión original y personal acerca de lo aprendido en esta semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
